{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90f32e62-545f-4334-ad58-83358ab613fe",
   "metadata": {},
   "source": [
    "### Extract and Transform AHRQ Survey data, filtering for SDOH topics.\n",
    "Extract and clean AHRQ survey data. Save a dictionary to be used for LangChain SQLDatabase tool.  \n",
    "Provide unction out_AHRQCountySDOH() to return dataframe. See https://www.ahrq.gov/sdoh/data-analytics/sdoh-data.html and https://www.ahrq.gov/sites/default/files/wysiwyg/sdoh/SDOH-Data-Sources-Documentation-v1-Final.pdf\n",
    "\n",
    "Input parameters:\n",
    "- parm_AHRQCountySDOH_years: list of survey years\n",
    "- parm_AHRQCountySDOH_surveys: list of surveys to extract\n",
    "- parm_AHRQCountySDOH_questions: CDCW and CHR have some SDOH questions which could be used (add these)\n",
    "\n",
    "Typical surveys to use include:\n",
    "\n",
    "[\"ACS\", \"AHA\", \"AMFAR\", \"CCBP\", \"CDCSVI\", \"CEN\", \"CRDC\", \"EPAA\", \"FARA\", \"FEA\", \"HHC\", \"HIFLD\", \"HRSA\", \"MHSVI\", \"MP\", \"NCHS\", \"NEPHTN\", \"NHC\", \"NOAAC\", \"NOAAS\", \"POS\", \"SAHIE\", \"SAIPE\", \"SEDA\"]\n",
    "\n",
    "These surveys are health outcomes and would not be used as SDOH:\n",
    "\n",
    "    AHRF, CDCA, CDCAP, CDCP, CDCW, CHR and MGV\n",
    "\n",
    "    \n",
    "However, CDCW and CHR have some SDOH questions which could be used in the list of questions:\n",
    "\n",
    "[\"CDCW_INJURY_DTH_RATE\", \"CDCW_TRANSPORT_DTH_RATE\", \"CDCW_SELFHARM_DTH_RATE\", \"CDCW_ASSAULT_DTH_RATE\", \"CHR_TOT_MENTAL_PROV\", \"CHR_MENTAL_PROV_RATE\", \"CHR_SEGREG_BLACK\", \"CHR_PCT_ALCOHOL_DRIV_DEATH\", \"CHR_PCT_EXCESS_DRINK\", \"CHR_PCT_FOOD\", \"CHR_SEGREG_BLACK\", \"CHR_SEGREG_NON_WHITE\"]\n",
    "\n",
    "Note 2018 has some behavioral health questions which could be used:\n",
    "\n",
    "[\"CDCP_NO_PHY_ACTV_ADULT_A\", \"CDCP_NO_PHY_ACTV_ADULT_C\", \"CDCP_SLEEP_LESS7HR_ADULT_A\", \"CDCP_SLEEP_LESS7HR_ADULT_C\"]\n",
    "    \n",
    "CAF are County Adjacent FIPS codes which could be considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa81f8ea-0172-4673-af7d-11c42918c611",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import requests\n",
    "import re\n",
    "import pickle\n",
    "import sys\n",
    "import time\n",
    "from io import BytesIO\n",
    "from typing import Optional, Sequence\n",
    "# for imports from agents\n",
    "sys.path.append('../agents')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbcc663-7351-4d84-ada5-b46955fdbd9e",
   "metadata": {},
   "source": [
    "### Parms\n",
    "From calling Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6bb6949-0052-425f-933c-570dc6c3fee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parm_AHRQCountySDOH_years = ['2015', '2016']\n",
    "# parm_AHRQCountySDOH_surveys = [\"ACS\", \"AHA\", \"AMFAR\", \"CAF\", \"CCBP\", \"CDCSVI\", \"CEN\", \"CRDC\", \"EPAA\", \"FARA\", \"FEA\", \"HHC\", \"HIFLD\", \"HRSA\", \"MHSVI\", \"MP\", \"NCHS\", \"NEPHTN\", \"NHC\", \"NOAAS\", \"POS\", \"SAHIE\", \"SAIPE\", \"SEDA\"]\n",
    "# parm_AHRQCountySDOH_questions = [\"CDCW_INJURY_DTH_RATE\", \"CDCW_TRANSPORT_DTH_RATE\", \"CDCW_SELFHARM_DTH_RATE\", \"CDCW_ASSAULT_DTH_RATE\", \"CHR_TOT_MENTAL_PROV\", \"CHR_MENTAL_PROV_RATE\", \"CHR_SEGREG_BLACK\", \"CHR_PCT_ALCOHOL_DRIV_DEATH\", \"CHR_PCT_EXCESS_DRINK\", \"CHR_PCT_FOOD\", \"CHR_SEGREG_BLACK\", \"CHR_SEGREG_NON_WHITE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67772fd9-a166-43d3-a1fa-a0aa7f28d060",
   "metadata": {},
   "source": [
    "### Download Method\n",
    "If we are running in a container, download can get CloudFront 403 meaning the site is blocking “non-browser” clients. Fix it by sending browser-like headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aebef40b-1611-47e9-b8f1-60ecbf90fdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_excel_with_browser_headers(url: str, out_path: str = None, session: requests.Session = None, timeout: int = 30) -> bytes:\n",
    "    headers = {\n",
    "        \"User-Agent\": (\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                       \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                       \"Chrome/120.0.0.0 Safari/537.36\"),\n",
    "        \"Accept\": \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\",\n",
    "        # \"Referer\": \"https://www.ahrq.gov/sdoh/index.html\",\n",
    "    }\n",
    "    s = session or requests.Session()\n",
    "    r = s.get(url, headers=headers, timeout=timeout)\n",
    "    r.raise_for_status()\n",
    "    content = r.content\n",
    "    if out_path:\n",
    "        with open(out_path, \"wb\") as f:\n",
    "            f.write(content)\n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb037498-c78b-47cc-9152-f263c0b38b42",
   "metadata": {},
   "source": [
    "### Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "883bb635-9ee5-40cc-86f4-b20a5eacdb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AHRQCountySDOH_year = parm_AHRQCountySDOH_years.pop(0)\n",
    "# url = 'https://www.ahrq.gov/sites/default/files/wysiwyg/sdoh/SDOH_'+  AHRQCountySDOH_year +'_COUNTY_1_0.xlsx'\n",
    "# out_path = download_excel_with_browser_headers(url, \"./ahrq\"+ AHRQCountySDOH_year +\".xlsx\")\n",
    "# dfAHRQCountySDOH = pd.read_excel(out_path, sheet_name=\"Data\", engine=\"openpyxl\")\n",
    "# dfAHRQCountySDOH = dfAHRQCountySDOH.drop(dfAHRQCountySDOH.columns[[ 0,1,2,5,6 ]],axis = 1)\n",
    "# dfAHRQCountySDOH['YEAR'] =  AHRQCountySDOH_year\n",
    "\n",
    "# # Import the remaining excel files and append to dataframe\n",
    "# for AHRQCountySDOH_year in parm_AHRQCountySDOH_years:\n",
    "#     out_path = download_excel_with_browser_headers(url, \"./ahrq\"+ AHRQCountySDOH_year +\".xlsx\")\n",
    "#     dfAHRQCountySDOHnext = pd.read_excel(out_path, sheet_name=\"Data\", engine=\"openpyxl\")\n",
    "#     dfAHRQCountySDOHnext = dfAHRQCountySDOHnext.drop(dfAHRQCountySDOHnext.columns[[ 0,1,2,5,6 ]],axis = 1)\n",
    "#     dfAHRQCountySDOHnext['YEAR'] =  AHRQCountySDOH_year\n",
    "#     dfAHRQCountySDOH = pd.concat([dfAHRQCountySDOH, dfAHRQCountySDOHnext], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "400a8741-dabc-4764-9bd6-de4036d099d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parm_AHRQCountySDOH_years' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m failed_years = []\n\u001b[32m      3\u001b[39m session = requests.Session()\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m yr \u001b[38;5;129;01min\u001b[39;00m \u001b[43mparm_AHRQCountySDOH_years\u001b[49m:\n\u001b[32m      6\u001b[39m     url = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mhttps://www.ahrq.gov/sites/default/files/wysiwyg/sdoh/SDOH_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_COUNTY_1_0.xlsx\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      7\u001b[39m     out_path = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m./ahrq\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.xlsx\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'parm_AHRQCountySDOH_years' is not defined"
     ]
    }
   ],
   "source": [
    "df_list = []\n",
    "failed_years = []\n",
    "session = requests.Session()\n",
    "\n",
    "for yr in parm_AHRQCountySDOH_years:\n",
    "    url = f'https://www.ahrq.gov/sites/default/files/wysiwyg/sdoh/SDOH_{yr}_COUNTY_1_0.xlsx'\n",
    "    out_path = f\"./ahrq{yr}.xlsx\"\n",
    "    try:\n",
    "        # small retry loop for transient failures\n",
    "        attempts = 0\n",
    "        while True:\n",
    "            attempts += 1\n",
    "            try:\n",
    "                excel_bytes = download_excel_with_browser_headers(url, out_path=out_path, session=session)\n",
    "                break\n",
    "            except requests.HTTPError as e:\n",
    "                if attempts >= 3:\n",
    "                    raise\n",
    "                time.sleep(1 * attempts)\n",
    "        # read directly from bytes (avoids needing to rely on disk if you want)\n",
    "        df = pd.read_excel(pd.io.common.BytesIO(excel_bytes), sheet_name=\"Data\", engine=\"openpyxl\")\n",
    "        # replicate your column-dropping and YEAR assignment\n",
    "        df = df.drop(df.columns[[0, 1, 2, 5, 6]], axis=1)\n",
    "        df['YEAR'] = yr\n",
    "        df_list.append(df)\n",
    "        print(f\"Loaded year {yr} ({len(df)} rows).\")\n",
    "    except Exception as e:\n",
    "        failed_years.append((yr, str(e)))\n",
    "        print(f\"Failed to load year {yr}: {e}\")\n",
    "\n",
    "# concatenate all successfully loaded years\n",
    "if df_list:\n",
    "    dfAHRQCountySDOH = pd.concat(df_list, ignore_index=True)\n",
    "else:\n",
    "    dfAHRQCountySDOH = pd.DataFrame()  # empty fallback\n",
    "\n",
    "if failed_years:\n",
    "    print(\"Some years failed to load:\", failed_years)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b50d1d5-1cf8-4fe5-9532-70149201feee",
   "metadata": {},
   "source": [
    "### Clean data\n",
    "Convert to numeric, forcing non-convertible values to NaN and remove county from names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95368a20-b534-43f5-9cf9-9c157695b56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAHRQCountySDOH.iloc[:, 3:] = dfAHRQCountySDOH.iloc[:, 3:].apply(pd.to_numeric, errors='coerce')\n",
    "dfAHRQCountySDOH['COUNTY'] = dfAHRQCountySDOH['COUNTY'].str.replace(' County','')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cc78b7-21e8-4911-b1a3-a32c54f61c47",
   "metadata": {},
   "source": [
    "### Filter to SDOH surverys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b05f493-651e-4787-a511-916bb51d8421",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAHRQCountySDOHred = dfAHRQCountySDOH[[\"STATE\", \"COUNTY\", \"YEAR\"]] \n",
    "\n",
    "dfAHRQCountySDOHsel = dfAHRQCountySDOH[dfAHRQCountySDOH.columns[pd.Series(dfAHRQCountySDOH.columns).str.startswith(tuple(parm_AHRQCountySDOH_surveys))]]\n",
    "dfAHRQCountySDOHred2 = pd.concat([dfAHRQCountySDOHred, dfAHRQCountySDOHsel], axis=1)\n",
    "\n",
    "dfAHRQCountySDOHsel = dfAHRQCountySDOH[parm_AHRQCountySDOH_questions]\n",
    "dfAHRQCountySDOHred = pd.concat([dfAHRQCountySDOHred2, dfAHRQCountySDOHsel], axis=1)\n",
    "dfAHRQCountySDOHnew = dfAHRQCountySDOHred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a574baee-8aa8-4b2e-9bc5-8eb02c88160b",
   "metadata": {},
   "source": [
    "### Missing values\n",
    "Commented out, keep all columns for now.\n",
    "\n",
    "Remove columns missing more than 30%.  Then impute missing data using KNN imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0b9ee2-5002-43a8-a89b-ad6c70fe09e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # drop columns that are more than 30% null\n",
    "# dfAHRQCountySDOHnew = dfAHRQCountySDOHnew.dropna(axis = 1, thresh=len(dfAHRQCountySDOHnew)*.7)\n",
    "\n",
    "# from sklearn.impute import KNNImputer\n",
    "# imputer = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "# dfAHRQCountySDOHnew.iloc[:,3::] = imputer.fit_transform(dfAHRQCountySDOHnew.iloc[:,3::])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce408973-863a-4a61-aa84-75c78fee2df2",
   "metadata": {},
   "source": [
    "### Method to get SDOH Code Book, filter for SDOH data and build dictionary of column descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caa4318-6d13-48a1-9ecc-10c57ba68d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sdoh_codebook_as_custom_table_info(\n",
    "    codebook_url: str,\n",
    "    sheet_name: str,\n",
    "    table_name: str,\n",
    "    table_description: str = \"AHRQ SDOH dataset\",\n",
    "    out_path: str = \"./ahrq_codebook.xlsx\",\n",
    "    allowed_prefixes: Sequence[str] | None = None,\n",
    "    allowed_questions: Sequence[str] | None = None,\n",
    "    verbose: bool = True\n",
    ") -> dict[str, dict]:\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    codebook_url : str\n",
    "        HTTPS URL to the Codebook file.\n",
    "    sheet_name : str\n",
    "        Sheet name to load from the Excel workbook (required).\n",
    "    table_name : str\n",
    "        Table name as it exists in the database.\n",
    "    table_description : str, optional\n",
    "        Description of the table contents.\n",
    "    out_path : str, optional\n",
    "        Local file path to save the codebook.\n",
    "    allowed_prefixes : list[str] or None\n",
    "        Keep variables that start with any of these prefixes (case-insensitive).\n",
    "    allowed_questions : list[str] or None\n",
    "        Keep these exact variable names as well (case-insensitive).\n",
    "    verbose : bool\n",
    "        Print summary information.\n",
    "\n",
    "    Returns\n",
    "    dict[str, dict]\n",
    "        custom_table_info structure, e.g.\n",
    "        {\n",
    "            \"table_name\": {\n",
    "                \"table_description\": \"...\",\n",
    "                \"columns\": {\n",
    "                    \"col1\": \"Human description\",\n",
    "                    \"col2\": \"Human description\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    \"\"\"\n",
    " # Download (may return bytes or be a path written to out_path)\n",
    "    file_or_bytes = download_excel_with_browser_headers(codebook_url, out_path=out_path)\n",
    "\n",
    "    # DIAGNOSTIC: Check what columns actually exist\n",
    "    print(f\"Codebook columns: {list(df.columns)}\")\n",
    "    print(f\"First few rows:\\n{df.head(3)}\")\n",
    "\n",
    "    # Normalize to file-like object if bytes were returned\n",
    "    if isinstance(file_or_bytes, (bytes, bytearray)):\n",
    "        excel_source = BytesIO(file_or_bytes)\n",
    "    else:\n",
    "        excel_source = file_or_bytes  # file path or file-like object; pandas accepts it\n",
    "\n",
    "    # Read only the requested sheet (let pandas raise if sheet not present)\n",
    "    df = pd.read_excel(excel_source, sheet_name=sheet_name, engine=\"openpyxl\")\n",
    "\n",
    "    # DIAGNOSTIC: Check what columns actually exist\n",
    "    print(f\"Codebook columns: {list(df.columns)}\")\n",
    "    print(f\"First few rows:\\n{df.head(3)}\")\n",
    "\n",
    "    # Find variable, label, and data source columns\n",
    "    var_col = next(\n",
    "        (c for c in df.columns if re.search(r'\\b(var(iable)?(\\s*name)?|short\\s*name)\\b', str(c), re.I)),\n",
    "        None\n",
    "    )\n",
    "    label_col = next(\n",
    "        (c for c in df.columns if re.search(r'\\b(label|description|long\\s*name|title)\\b', str(c), re.I)),\n",
    "        None\n",
    "    )\n",
    "    source_col = next(\n",
    "        (c for c in df.columns if re.search(r'\\b(data\\s*source|source)\\b', str(c), re.I)),\n",
    "        None\n",
    "    )\n",
    "\n",
    "    if var_col is None or label_col is None:\n",
    "        raise ValueError(\n",
    "            f\"Could not identify variable/label columns in sheet '{sheet_name}'. Columns seen: {list(df.columns)}\"\n",
    "        )\n",
    "\n",
    "    # Build a small dataframe of vars -> labels (clean NA)\n",
    "    if source_col:\n",
    "        vars_df = df[[var_col, label_col, source_col]].dropna(subset=[var_col]).copy()\n",
    "        vars_df.columns = [\"variable\", \"label\", \"source\"]\n",
    "        vars_df[\"source\"] = vars_df[\"source\"].astype(str).str.strip()\n",
    "    else:\n",
    "        vars_df = df[[var_col, label_col]].dropna(subset=[var_col]).copy()\n",
    "        vars_df.columns = [\"variable\", \"label\"]\n",
    "        vars_df[\"source\"] = \"\"  # Empty column if not found\n",
    "\n",
    "    vars_df[\"variable\"] = vars_df[\"variable\"].astype(str).str.strip()\n",
    "    vars_df[\"label\"] = vars_df[\"label\"].astype(str).str.strip().fillna(\"\")\n",
    "\n",
    "    # Prepare filters (case-insensitive)\n",
    "    kept_mask = pd.Series(False, index=vars_df.index)\n",
    "\n",
    "    if allowed_prefixes:\n",
    "        prefixes_tuple = tuple(str(p).strip().lower() for p in allowed_prefixes if str(p).strip())\n",
    "        if prefixes_tuple:\n",
    "            # Filter by Data Source column if it exists, otherwise fall back to variable name\n",
    "            if source_col and not vars_df[\"source\"].isna().all():\n",
    "                kept_mask = kept_mask | vars_df[\"source\"].str.lower().isin([p.lower() for p in allowed_prefixes])\n",
    "            else:\n",
    "                kept_mask = kept_mask | vars_df[\"variable\"].str.lower().str.startswith(prefixes_tuple)\n",
    "        if allowed_questions:\n",
    "            qset = {str(q).strip().lower() for q in allowed_questions if str(q).strip()}\n",
    "            if qset:\n",
    "                kept_mask = kept_mask | vars_df[\"variable\"].str.lower().isin(qset)\n",
    "\n",
    "    # If no filters provided, keep all\n",
    "    if not allowed_prefixes and not allowed_questions:\n",
    "        kept_mask = pd.Series(True, index=vars_df.index)\n",
    "\n",
    "    kept_df = vars_df[kept_mask].copy()\n",
    "    dropped_df = vars_df[~kept_mask].copy()\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Codebook sheet '{sheet_name}': total vars={len(vars_df)}, kept={len(kept_df)}, dropped={len(dropped_df)}\")\n",
    "        if len(dropped_df) and len(dropped_df) <= 40:\n",
    "            print(\"Dropped sample:\", dropped_df[\"variable\"].tolist()[:20])\n",
    "\n",
    "    # Build columns dict in the expected format\n",
    "    columns = {row[\"variable\"]: row[\"label\"] for _, row in kept_df.iterrows()}\n",
    "\n",
    "    custom_table_info = {\n",
    "        table_name: {\n",
    "            \"table_description\": table_description,\n",
    "            \"columns\": columns\n",
    "        }\n",
    "    }\n",
    "    return custom_table_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7626080f",
   "metadata": {},
   "source": [
    "## Method to normalize column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066efad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_colname(name: str) -> str:\n",
    "    \"\"\"\n",
    "    1) lower-case\n",
    "    2) replace any non-alphanumeric character with underscore\n",
    "    3) collapse multiple underscores\n",
    "    4) strip leading/trailing underscores\n",
    "    5) if starts with digit -> prefix with 'col_'\n",
    "    6) special-case a 'year' column -> rename to 'year_col' to avoid reserved-word collisions\n",
    "    \"\"\"\n",
    "    if name is None:\n",
    "        return name\n",
    "    s = str(name).lower()\n",
    "    # replace non-alphanumeric with underscore\n",
    "    s = re.sub(r'[^a-z0-9]', '_', s)\n",
    "    # collapse multiple underscores\n",
    "    s = re.sub(r'_+', '_', s)\n",
    "    s = s.strip('_')\n",
    "    # if empty after cleaning\n",
    "    if not s:\n",
    "        s = 'col'\n",
    "    # prefix if starts with digit\n",
    "    if re.match(r'^[0-9]', s):\n",
    "        s = 'col_' + s\n",
    "    # avoid a bare \"year\" column name that can sometimes be problematic\n",
    "    if s == 'year':\n",
    "        s = 'year'\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4110aa61",
   "metadata": {},
   "source": [
    "### Method to normalize names in the mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1345602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_mapping_columns(mapping: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Normalize all column names in the mapping using normalize_colname().\n",
    "    \"\"\"\n",
    "    normalized_mapping = {}\n",
    "    for table, tinfo in mapping.items():\n",
    "        normalized_cols = {normalize_colname(col): desc for col, desc in tinfo.get(\"columns\", {}).items()}\n",
    "        normalized_mapping[table] = {\n",
    "            \"table_description\": tinfo.get(\"table_description\", \"\"),\n",
    "            \"columns\": normalized_cols\n",
    "        }\n",
    "    return normalized_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08bbdcc-8444-42c1-81ea-43ad3172376c",
   "metadata": {},
   "source": [
    "### Build Database Dictionary\n",
    "Get column descriptors, normalize columns and create dictionary.  Note this is simple as it assumes\n",
    "we are rebuilding the dictionary each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d05094b-b0c5-48fb-b465-e48ebb7cce7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dictionary_tool import DictionaryLocalTool\n",
    "\n",
    "mapping = load_sdoh_codebook_as_custom_table_info(\n",
    "    \"https://www.ahrq.gov/sites/default/files/wysiwyg/sdoh/SDOH_2020_Codebook_1_0.xlsx\",\n",
    "    \"County\",\n",
    "    \"sdoh_surveys\",\n",
    "    \"AHRQ SDOH Surveys\",\n",
    "    \"./ahrq_codebook.xlsx\",\n",
    "    allowed_prefixes=parm_AHRQCountySDOH_surveys,\n",
    "    allowed_questions=parm_AHRQCountySDOH_questions\n",
    ")\n",
    "\n",
    "mapping = normalize_mapping_columns(mapping)\n",
    "\n",
    "dt = DictionaryLocalTool(persist_dir=\"../data\", model_name=\"all-MiniLM-L6-v2\", search_k=6)\n",
    "dt.create_index(mapping, dedupe=True, overwrite=True )  # or dt.rebuild_index(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57db6acd-e546-49d6-aa39-4da84895a1eb",
   "metadata": {},
   "source": [
    "### Load function\n",
    "Function for calling notebook to get dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1926a73-cbc9-4bcd-a5ca-42adad8ae45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove formatting issues by converting YEAR to int\n",
    "dfAHRQCountySDOHnew[\"YEAR\"] = pd.to_numeric(dfAHRQCountySDOHnew[\"YEAR\"])\n",
    "def out_AHRQCountySDOH():\n",
    "   return dfAHRQCountySDOHnew"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
