{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "472f6960",
   "metadata": {},
   "source": [
    "# define_sdoh_database\n",
    "\n",
    "Recreate and load the SDOH_Surveys table using data from ETL notebook: dataAHRQCountySDOH.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f38c5130-e202-4626-9cba-1308d546eeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sqlalchemy import create_engine, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67a1432a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'postgresql://myuser:mypassword@db:5432/mydb'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set parms for ETL notebook.\n",
    "parm_AHRQCountySDOH_years = ['2017', '2018', '2019', '2020']\n",
    "parm_AHRQCountySDOH_surveys = [\"ACS\", \"AHA\", \"AMFAR\", \"CAF\", \"CCBP\", \"CDCSVI\", \"CEN\", \"CRDC\", \"EPAA\", \"FARA\", \"FEA\", \"HHC\", \"HIFLD\", \"HRSA\", \"MHSVI\", \"MP\", \"NCHS\", \"NEPHTN\", \"NHC\", \"NOAAS\", \"POS\", \"SAHIE\", \"SAIPE\", \"SEDA\"]\n",
    "parm_AHRQCountySDOH_questions = [\"CDCW_INJURY_DTH_RATE\", \"CDCW_TRANSPORT_DTH_RATE\", \"CDCW_SELFHARM_DTH_RATE\", \"CDCW_ASSAULT_DTH_RATE\", \"CHR_TOT_MENTAL_PROV\", \"CHR_MENTAL_PROV_RATE\", \"CHR_SEGREG_BLACK\", \"CHR_PCT_ALCOHOL_DRIV_DEATH\", \"CHR_PCT_EXCESS_DRINK\", \"CHR_PCT_FOOD\", \"CHR_SEGREG_BLACK\", \"CHR_SEGREG_NON_WHITE\"]\n",
    "\n",
    "DB_URI = os.environ.get(\"DB_URI\")\n",
    "if not DB_URI:\n",
    "    raise EnvironmentError(\n",
    "        \"DB_URI is not set.\"\n",
    "    )\n",
    "DB_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4789da",
   "metadata": {},
   "source": [
    "## Run ETL notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c4c024e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded year 2017 (3232 rows).\n",
      "Loaded year 2018 (3232 rows).\n",
      "Loaded year 2019 (3232 rows).\n",
      "Loaded year 2020 (3229 rows).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/tmp/ipykernel_208/1844520386.py:37: FutureWarning: Passing bytes to 'read_excel' is deprecated and will be removed in a future version. To read from a byte string, wrap it in a `BytesIO` object.\n",
      "  all_sheets = pd.read_excel(file_path, sheet_name=None, engine=\"openpyxl\")\n",
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    }
   ],
   "source": [
    "%run dataAHRQCountySDOH.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bbfdf2",
   "metadata": {},
   "source": [
    "## Collect DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52a0e95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = out_AHRQCountySDOH()\n",
    "\n",
    "if not isinstance(df, pd.DataFrame):\n",
    "    raise TypeError(f\"out_AHRQCountySDOH returned {type(df)}, expected pandas.DataFrame\")\n",
    "\n",
    "# print(\"Rows:\", len(df), \"Columns:\", list(df.columns))\n",
    "# df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6642bf20",
   "metadata": {},
   "source": [
    "## Method to normalize column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b210792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_colname(name: str) -> str:\n",
    "    \"\"\"\n",
    "    1) lower-case\n",
    "    2) replace any non-alphanumeric character with underscore\n",
    "    3) collapse multiple underscores\n",
    "    4) strip leading/trailing underscores\n",
    "    5) if starts with digit -> prefix with 'col_'\n",
    "    6) special-case a 'year' column -> rename to 'year_col' to avoid reserved-word collisions\n",
    "    \"\"\"\n",
    "    if name is None:\n",
    "        return name\n",
    "    s = str(name).lower()\n",
    "    # replace non-alphanumeric with underscore\n",
    "    s = re.sub(r'[^a-z0-9]', '_', s)\n",
    "    # collapse multiple underscores\n",
    "    s = re.sub(r'_+', '_', s)\n",
    "    s = s.strip('_')\n",
    "    # if empty after cleaning\n",
    "    if not s:\n",
    "        s = 'col'\n",
    "    # prefix if starts with digit\n",
    "    if re.match(r'^[0-9]', s):\n",
    "        s = 'col_' + s\n",
    "    # avoid a bare \"year\" column name that can sometimes be problematic\n",
    "    if s == 'year':\n",
    "        s = 'sdoh_year'\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87abf30d",
   "metadata": {},
   "source": [
    "## Normalize Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "945f5ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized column names (first 50): ['state', 'county', 'sdoh_year', 'acs_tot_pop_wt', 'acs_tot_pop_us_above1', 'acs_tot_pop_above5', 'acs_tot_pop_above15', 'acs_tot_pop_above16', 'acs_tot_pop_16_19', 'acs_tot_pop_above25', 'acs_tot_civil_pop_above18', 'acs_tot_civil_vet_pop_above25', 'acs_tot_own_child_below17', 'acs_tot_worker_nwfh', 'acs_tot_worker_hh', 'acs_tot_civilian_labor', 'acs_tot_civil_employ_pop', 'acs_tot_pop_pov', 'acs_tot_civil_noninst_pop_pov', 'acs_tot_civil_pop_pov', 'acs_tot_grandchildren_gp', 'acs_tot_hu', 'acs_tot_hh', 'acs_avg_hh_size', 'acs_tot_civil_noninst_pop', 'acs_tot_civil_vet_pop', 'acs_pct_child_disab', 'acs_pct_disable', 'acs_pct_nonvet_disable_18_64', 'acs_pct_vet_disable_18_64', 'acs_pct_male', 'acs_pct_female', 'acs_pct_ctz_us_born', 'acs_pct_ctz_nonus_born', 'acs_pct_foreign_born', 'acs_pct_non_citizen', 'acs_pct_ctz_naturalized', 'acs_pct_nonctn_1990', 'acs_pct_nonctn_1999', 'acs_pct_nonctn_2000', 'acs_pct_nonctn_2010', 'acs_pct_api_lang', 'acs_pct_engl_not_all', 'acs_pct_engl_not_well', 'acs_pct_engl_very_well', 'acs_pct_engl_well', 'acs_pct_english', 'acs_pct_hh_limit_english', 'acs_pct_oth_eurp', 'acs_pct_oth_lang']\n"
     ]
    }
   ],
   "source": [
    "# apply normalization\n",
    "new_cols = [normalize_colname(c) for c in df.columns]\n",
    "# # detect collisions (two different original names producing same normalized name)\n",
    "# from collections import defaultdict\n",
    "# mapping = defaultdict(list)\n",
    "# for orig, new in zip(df.columns, new_cols):\n",
    "#     mapping[new].append(orig)\n",
    "\n",
    "# collisions = {k: v for k, v in mapping.items() if len(v) > 1}\n",
    "# if collisions:\n",
    "#     # break collisions by appending numeric suffixes in stable order\n",
    "#     resolved = {}\n",
    "#     for new, origs in collisions.items():\n",
    "#         for i, orig in enumerate(origs, start=1):\n",
    "#             resolved_name = f\"{new}_{i}\"\n",
    "#             # replace the first occurrence in new_cols for this original name\n",
    "#             idx = list(df.columns).index(orig)\n",
    "#             new_cols[idx] = resolved_name\n",
    "\n",
    "# assign cleaned column names\n",
    "df.columns = new_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b728c0d-a9d9-488f-9abe-8e86ece827aa",
   "metadata": {},
   "source": [
    "## Delete duplicate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10009610-1922-4782-b323-cd6051792f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed duplicate columns: ['chr_segreg_black']\n"
     ]
    }
   ],
   "source": [
    "# Detect duplicate columns and remove them\n",
    "seen = set()\n",
    "duplicates = []\n",
    "\n",
    "for col in df.columns:\n",
    "    if col in seen:\n",
    "        duplicates.append(col)\n",
    "    else:\n",
    "        seen.add(col)\n",
    "\n",
    "# Drop duplicates\n",
    "df = df.loc[:, ~df.columns.duplicated()]\n",
    "\n",
    "# Print removed columns\n",
    "if duplicates:\n",
    "    print(\"Removed duplicate columns:\", duplicates)\n",
    "else:\n",
    "    print(\"No duplicate columns found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafd5ac4",
   "metadata": {},
   "source": [
    "## Drop & Recreate `SDOH_Surveys`, then Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d412415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped table \"sdoh_surveys\" (if existed).\n",
      "Loaded 12925 rows into \"sdoh_surveys\".\n"
     ]
    }
   ],
   "source": [
    "engine = create_engine(DB_URI)\n",
    "TABLE_NAME = \"sdoh_surveys\"\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(text(f'DROP TABLE IF EXISTS \"{TABLE_NAME}\" CASCADE;'))\n",
    "    print(f'Dropped table \"{TABLE_NAME}\" (if existed).')\n",
    "\n",
    "# Recreate schema and load rows\n",
    "df.to_sql(TABLE_NAME, engine, if_exists=\"replace\", index=False)\n",
    "print(f'Loaded {len(df)} rows into \"{TABLE_NAME}\".')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
